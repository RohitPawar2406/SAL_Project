import os
import random
from datasets import load_dataset
from aksharamukha import transliterate

# -------------------------------
# 1ï¸âƒ£ Confirm HF_HOME setup
# -------------------------------
hf_home = os.environ.get("HF_HOME", None)
print(f"HF_HOME currently set to: {hf_home if hf_home else '~/.cache/huggingface'}")

# -------------------------------
# 2ï¸âƒ£ Load full Santali dataset
# -------------------------------
print("ğŸ”¹ Loading full Santali IndicVoices dataset...")

santali_ds = load_dataset(
    "ai4bharat/IndicVoices",
    data_dir="santali",
    split="train",
)

print(f"âœ… Dataset loaded with {len(santali_ds)} samples.\n")

# -------------------------------
# 3ï¸âƒ£ Transliteration function (Ol Chiki â†’ Latin)
# -------------------------------
def add_transliteration(batch):
    text = batch.get("sentence") or batch.get("text")
    if not text:
        batch["latin_text"] = ""
        return batch

    # Use Aksharamukha converter
    batch["latin_text"] = transliterate.process("Ol Chiki", "Latin", text)
    return batch

# -------------------------------
# 4ï¸âƒ£ Apply transliteration
# -------------------------------
print("ğŸ”¹ Applying Aksharamukha transliteration (Ol Chiki â†’ Latin)...")
santali_ds = santali_ds.map(add_transliteration)

# -------------------------------
# 5ï¸âƒ£ Print sample
# -------------------------------
idx = random.randint(0, len(santali_ds) - 1)
print("\nExample:")
print("Ol Chiki :", santali_ds[idx]["sentence"])
print("Latin    :", santali_ds[idx]["latin_text"])

# -------------------------------
# 6ï¸âƒ£ Save to disk
# -------------------------------
save_path = os.path.expanduser("/scratch/rohit.pawar/sal_dir_santali")
santali_ds.save_to_disk(save_path)

print(f"\nâœ… Transliterated Santali dataset saved at: {save_path}")
